{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"comments_data/\"\n",
    "angry = pd.read_csv(os.path.join(path,\"angry.txt\"),header=None)\n",
    "sad = pd.read_csv(os.path.join(path,\"sad.txt\"),header=None)\n",
    "love = pd.read_csv(os.path.join(path,\"love.txt\"),header=None)\n",
    "haha = pd.read_csv(os.path.join(path,\"haha.txt\"),header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# angry[\"label\"] = 0\n",
    "# sad[\"label\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### labels angry 0 sad 1 haha 2 love 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_dataframe = []\n",
    "total_dataframe.append(angry)\n",
    "total_dataframe.append(sad)\n",
    "total_dataframe.append(haha)\n",
    "total_dataframe.append(love)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1953, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_dataframe[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "def create_labels(data_frame):\n",
    "    total_labels = []\n",
    "    for i in range(4):\n",
    "        total_labels.append(np.zeros(data_frame[i].shape))\n",
    "        total_labels[i]+=i\n",
    "    labels_array = copy.deepcopy(total_labels[0])\n",
    "    for i in range(3):\n",
    "        labels_array = np.append(labels_array,total_labels[i+1])\n",
    "    return np.array(labels_array,dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "labels_array = create_labels(total_dataframe)\n",
    "print(labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1520\n",
      "(1520,)\n"
     ]
    }
   ],
   "source": [
    "def data_split(data_frame,labels):\n",
    "    index = np.arange(len(labels_array))\n",
    "    np.random.shuffle(index)\n",
    "    start = int(len(index)/10)\n",
    "    print(start)\n",
    "    test_index = index[:start]\n",
    "    train_index = index[start:len(index)]\n",
    "    print(test_index.shape)\n",
    "    train_values,train_labels = data_frame.values[train_index],labels_array[train_index]\n",
    "    test_values,test_labels = data_frame.values[test_index],labels_array[test_index]\n",
    "    \n",
    "    train_values = pd.DataFrame(train_values)\n",
    "    train_values.to_csv(os.path.join(path,\"total_train_value.csv\"))\n",
    "    \n",
    "    test_values = pd.DataFrame(test_values)\n",
    "    test_values.to_csv(os.path.join(path,\"total_test_value.csv\"))\n",
    "    \n",
    "    train_labels = pd.DataFrame(train_labels)\n",
    "    train_labels.to_csv(os.path.join(path,\"total_train_label.csv\"))\n",
    "    \n",
    "    test_labels = pd.DataFrame(test_labels)\n",
    "    test_labels.to_csv(os.path.join(path,\"total_test_label.csv\"))\n",
    "\n",
    "data_split(angry.append(sad).append(haha).append(love),labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 442\n"
     ]
    }
   ],
   "source": [
    "def data_frame_integrate(data_frame_list):\n",
    "    assert len(data_frame_list) >= 2\n",
    "    res = data_frame_list[0]\n",
    "    for i in range(1,len(data_frame_list)):\n",
    "        res = res.append(data_frame_list[i])\n",
    "#     print(res.shape)\n",
    "    return res\n",
    "def data_balanced_split(data_frame_list):\n",
    "    length_list = [len(elem) for elem in data_frame_list]\n",
    "    min_length = np.min([len(elem) for elem in data_frame_list])\n",
    "    \n",
    "    random_index_list = [np.arange(len(elem)) for elem in data_frame_list]\n",
    "    for i in range(len(random_index_list)):\n",
    "        random.shuffle(random_index_list[i])\n",
    "    random_index_list = np.array([elem[:min_length] for elem in random_index_list])\n",
    "\n",
    "    offset_lam = lambda x,i: sum([x[j] for j in range(i)])\n",
    "#     sum_lam = lambda x: sum([len(elem) for elem in x])\n",
    "    offset_list = [offset_lam(length_list,i) for i in range(len(random_index_list))]\n",
    "    for i in range(len(data_frame_list)):\n",
    "        random_index_list[i]+= offset_list[i]\n",
    "        \n",
    "    for i in range(len(data_frame_list)):\n",
    "        assert (max(random_index_list[i]) - min(random_index_list[i])) > 0.9*len(data_frame_list[i])\n",
    "    assert (random_index_list[0]<random_index_list[1]).all()\n",
    "\n",
    "\n",
    "    index = random_index_list.reshape((min_length*len(data_frame_list),))\n",
    "    random.shuffle(index)\n",
    "#     print(index.shape)\n",
    "\n",
    "    start = int(index.shape[0]/10)\n",
    "    print(\"start\",start)\n",
    "#     labes_array = [np.zeros(len(data_frame_list)) for i in range]\n",
    "    test_index = index[:start]\n",
    "    train_index = index[start:len(index)]\n",
    "\n",
    "    data_frame = data_frame_integrate(data_frame_list)\n",
    "    \n",
    "    train_values,train_labels = data_frame.values[train_index],labels_array[train_index]\n",
    "    test_values,test_labels = data_frame.values[test_index],labels_array[test_index]\n",
    "#     print(test_index)\n",
    "    train_values = pd.DataFrame(train_values)\n",
    "    train_values.to_csv(os.path.join(path,\"balanced_train_value.csv\"))\n",
    "    \n",
    "    test_values = pd.DataFrame(test_values)\n",
    "    test_values.to_csv(os.path.join(path,\"balanced_test_value.csv\"))\n",
    "    \n",
    "    train_labels = pd.DataFrame(train_labels)\n",
    "    train_labels.to_csv(os.path.join(path,\"balanced_train_label.csv\"))\n",
    "    \n",
    "    test_labels = pd.DataFrame(test_labels)\n",
    "    test_labels.to_csv(os.path.join(path,\"balanced_test_label.csv\"))\n",
    "\n",
    "data_balanced_split(total_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### overview of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_to_word_array(data_frame):\n",
    "    temp = data_frame.values\n",
    "    new_array = [str(element).split(\" \") for element in temp]\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAD6RJREFUeJzt3X+s3XV9x/HnawXdoiYUuRDWll1m\nukRMZjUNkrA/UDcoYFZMRgLZtDEk9Q9IMHFZqv/gNCSYTF1MHAmOxpqojEwZzWjErmNx/iFSlAG1\nEu6wg2sbWoc/Y8ICvvfH+TQcy+29596ee4/3fp6P5OSc7/t8vt/v5xMO93W+n+/3fJuqQpLUn9+Z\ndAckSZNhAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ddakOzCf8847r6anpyfd\nDUlaVR599NEfV9XUQu1+qwNgenqagwcPTrobkrSqJPmfUdo5BSRJnTIAJKlTBoAkdcoAkKROGQCS\n1CkDQJI6ZQBIUqcMAEnqlAEgSZ36rf4l8Jma3vXARPZ75I5rJ7JfSVoMjwAkqVMGgCR1asEASLIp\nyUNJDic5lOTWVv9Ykh8leaw9rhla5yNJZpI8leSqofq2VptJsmt5hiRJGsUo5wBeAj5cVd9N8gbg\n0ST723ufqaq/G26c5BLgBuAtwO8D/5bkj9rbnwP+DJgFHkmyt6q+P46BSJIWZ8EAqKpjwLH2+hdJ\nDgMb5lllO3BPVb0I/DDJDHBpe2+mqp4BSHJPa2sASNIELOocQJJp4G3Aw610S5LHk+xOsr7VNgDP\nDa0222qnq0uSJmDkAEjyeuCrwIeq6ufAncCbgC0MjhA+dbLpHKvXPPVT97MzycEkB0+cODFq9yRJ\nizRSACQ5m8Ef/y9V1dcAqur5qnq5qn4NfJ5XpnlmgU1Dq28Ejs5T/w1VdVdVba2qrVNTC/6LZpKk\nJRrlKqAAdwOHq+rTQ/ULh5q9F3iyvd4L3JDktUkuBjYD3wEeATYnuTjJaxicKN47nmFIkhZrlKuA\nLgfeBzyR5LFW+yhwY5ItDKZxjgAfBKiqQ0nuZXBy9yXg5qp6GSDJLcCDwDpgd1UdGuNYJEmLMMpV\nQN9i7vn7ffOscztw+xz1ffOtJ0laOf4SWJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkA\nktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJ\nnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkTi0YAEk2\nJXkoyeEkh5Lc2urnJtmf5On2vL7Vk+SzSWaSPJ7k7UPb2tHaP51kx/INS5K0kFGOAF4CPlxVbwYu\nA25OcgmwCzhQVZuBA20Z4Gpgc3vsBO6EQWAAtwHvAC4FbjsZGpKklbdgAFTVsar6bnv9C+AwsAHY\nDuxpzfYA17XX24Ev1sC3gXOSXAhcBeyvqheq6ifAfmDbWEcjSRrZos4BJJkG3gY8DFxQVcdgEBLA\n+a3ZBuC5odVmW+10dUnSBIwcAEleD3wV+FBV/Xy+pnPUap76qfvZmeRgkoMnTpwYtXuSpEUaKQCS\nnM3gj/+Xquprrfx8m9qhPR9v9Vlg09DqG4Gj89R/Q1XdVVVbq2rr1NTUYsYiSVqEUa4CCnA3cLiq\nPj301l7g5JU8O4D7h+rvb1cDXQb8rE0RPQhcmWR9O/l7ZatJkibgrBHaXA68D3giyWOt9lHgDuDe\nJDcBzwLXt/f2AdcAM8CvgA8AVNULST4BPNLafbyqXhjLKCRJi7ZgAFTVt5h7/h7g3XO0L+Dm02xr\nN7B7MR2UJC0PfwksSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOjXK7wC0SNO7HpjYvo/cce3E9i1p\ndfEIQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmd\nMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1KkF\nAyDJ7iTHkzw5VPtYkh8leaw9rhl67yNJZpI8leSqofq2VptJsmv8Q5EkLcYoRwBfALbNUf9MVW1p\nj30ASS4BbgDe0tb5hyTrkqwDPgdcDVwC3NjaSpIm5KyFGlTVN5NMj7i97cA9VfUi8MMkM8Cl7b2Z\nqnoGIMk9re33F91jSdJYnMk5gFuSPN6miNa32gbguaE2s612urokaUKWGgB3Am8CtgDHgE+1euZo\nW/PUXyXJziQHkxw8ceLEErsnSVrIkgKgqp6vqper6tfA53llmmcW2DTUdCNwdJ76XNu+q6q2VtXW\nqamppXRPkjSCJQVAkguHFt8LnLxCaC9wQ5LXJrkY2Ax8B3gE2Jzk4iSvYXCieO/Suy1JOlMLngRO\n8hXgCuC8JLPAbcAVSbYwmMY5AnwQoKoOJbmXwcndl4Cbq+rltp1bgAeBdcDuqjo09tFIkkY2ylVA\nN85Rvnue9rcDt89R3wfsW1TvJEnLxl8CS1KnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNA\nkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSp\nUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdOmvSHdB4Te96YCL7PXLHtRPZr6Sl8whA\nkjplAEhSpwwASerUggGQZHeS40meHKqdm2R/kqfb8/pWT5LPJplJ8niStw+ts6O1fzrJjuUZjiRp\nVKMcAXwB2HZKbRdwoKo2AwfaMsDVwOb22AncCYPAAG4D3gFcCtx2MjQkSZOxYABU1TeBF04pbwf2\ntNd7gOuG6l+sgW8D5yS5ELgK2F9VL1TVT4D9vDpUJEkraKnnAC6oqmMA7fn8Vt8APDfUbrbVTleX\nJE3IuE8CZ45azVN/9QaSnUkOJjl44sSJsXZOkvSKpQbA821qh/Z8vNVngU1D7TYCR+epv0pV3VVV\nW6tq69TU1BK7J0layFIDYC9w8kqeHcD9Q/X3t6uBLgN+1qaIHgSuTLK+nfy9stUkSROy4K0gknwF\nuAI4L8ksg6t57gDuTXIT8CxwfWu+D7gGmAF+BXwAoKpeSPIJ4JHW7uNVdeqJZUnSClowAKrqxtO8\n9e452hZw82m2sxvYvajeSZKWjb8ElqROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXK\nAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwA\nSeqUASBJnTIAJKlTZ026A1obpnc9MJH9Hrnj2onsV1oLPAKQpE4ZAJLUKQNAkjplAEhSpwwASeqU\nASBJnTIAJKlTZxQASY4keSLJY0kOttq5SfYnebo9r2/1JPlskpkkjyd5+zgGIElamnEcAbyzqrZU\n1da2vAs4UFWbgQNtGeBqYHN77ATuHMO+JUlLtBxTQNuBPe31HuC6ofoXa+DbwDlJLlyG/UuSRnCm\nAVDAN5I8mmRnq11QVccA2vP5rb4BeG5o3dlWkyRNwJneC+jyqjqa5Hxgf5IfzNM2c9TqVY0GQbIT\n4KKLLjrD7kmSTueMjgCq6mh7Pg7cB1wKPH9yaqc9H2/NZ4FNQ6tvBI7Osc27qmprVW2dmpo6k+5J\nkuax5ABI8rokbzj5GrgSeBLYC+xozXYA97fXe4H3t6uBLgN+dnKqSJK08s5kCugC4L4kJ7fz5ar6\nepJHgHuT3AQ8C1zf2u8DrgFmgF8BHziDfUuSztCSA6CqngHeOkf9f4F3z1Ev4Oal7k+SNF7+EliS\nOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE6d6b2ApIma3vXAxPZ95I5rJ7ZvaRwMAGmJJhU+\nBo/GxSkgSeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqf8IZi0yvjrZ42LRwCS1CkD\nQJI6ZQBIUqc8ByBpZN4Ab23xCECSOmUASFKnnAKS9FvPS1+Xh0cAktQpA0CSOuUUkCTNYy1f+eQR\ngCR1ygCQpE4ZAJLUqRUPgCTbkjyVZCbJrpXevyRpYEUDIMk64HPA1cAlwI1JLlnJPkiSBlb6COBS\nYKaqnqmq/wPuAbavcB8kSax8AGwAnhtanm01SdIKW+nfAWSOWv1Gg2QnsLMt/jLJUwts8zzgx2Po\n22rV8/h7Hjv0Pf41P/Z88rRvjTL2PxhlHysdALPApqHljcDR4QZVdRdw16gbTHKwqraOp3urT8/j\n73ns0Pf4Hft4xr7SU0CPAJuTXJzkNcANwN4V7oMkiRU+Aqiql5LcAjwIrAN2V9WhleyDJGlgxe8F\nVFX7gH1j3OTI00VrVM/j73ns0Pf4HfsYpKoWbiVJWnO8FYQkdWpVB0Bvt5VIsjvJ8SRPDtXOTbI/\nydPtef0k+7hckmxK8lCSw0kOJbm11df8+JP8bpLvJPmvNva/bfWLkzzcxv5P7cKKNSnJuiTfS/Kv\nbbmnsR9J8kSSx5IcbLWxfO5XbQB0eluJLwDbTqntAg5U1WbgQFtei14CPlxVbwYuA25u/717GP+L\nwLuq6q3AFmBbksuATwKfaWP/CXDTBPu43G4FDg8t9zR2gHdW1Zahyz/H8rlftQFAh7eVqKpvAi+c\nUt4O7Gmv9wDXrWinVkhVHauq77bXv2Dwx2ADHYy/Bn7ZFs9ujwLeBfxzq6/JsQMk2QhcC/xjWw6d\njH0eY/ncr+YA8LYSAxdU1TEY/JEEzp9wf5ZdkmngbcDDdDL+NgXyGHAc2A/8N/DTqnqpNVnLn/+/\nB/4G+HVbfiP9jB0GYf+NJI+2OyXAmD73q/mfhFzwthJae5K8Hvgq8KGq+vngy+DaV1UvA1uSnAPc\nB7x5rmYr26vll+Q9wPGqejTJFSfLczRdc2MfcnlVHU1yPrA/yQ/GteHVfASw4G0lOvF8kgsB2vPx\nCfdn2SQ5m8Ef/y9V1ddauZvxA1TVT4H/YHAe5JwkJ7/ErdXP/+XAnyc5wmCa910Mjgh6GDsAVXW0\nPR9nEP6XMqbP/WoOAG8rMbAX2NFe7wDun2Bflk2b970bOFxVnx56a82PP8lU++ZPkt8D/pTBOZCH\ngL9ozdbk2KvqI1W1saqmGfw//u9V9Zd0MHaAJK9L8oaTr4ErgScZ0+d+Vf8QLMk1DL4NnLytxO0T\n7tKySvIV4AoGdwN8HrgN+BfgXuAi4Fng+qo69UTxqpfkT4D/BJ7glbngjzI4D7Cmx5/kjxmc6FvH\n4EvbvVX18SR/yOBb8bnA94C/qqoXJ9fT5dWmgP66qt7Ty9jbOO9ri2cBX66q25O8kTF87ld1AEiS\nlm41TwFJks6AASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqf+HztWU5kzEg1aAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ba4d470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of less than 50 words:  0.9508798582099\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats.mstats import mode\n",
    "import matplotlib.pyplot as plt\n",
    "angry_example = sentence_to_word_array(angry)\n",
    "length_array = np.array([len(elem) for elem in angry_example])\n",
    "# length_dict = np.\n",
    "short = length_array[length_array<50]\n",
    "plt.hist(short)\n",
    "plt.show()\n",
    "percentage = sum(length_array<50)/len(length_array)\n",
    "print(\"percentage of less than 50 words: \", percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenizer for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "total_comments = angry.append(sad).append(haha).append(love)\n",
    "\n",
    "def tokenizer_in_total(data_frame,max_tokenizer_words):\n",
    "    temp_tokenizer = Tokenizer(num_words=max_tokenizer_words+1,lower=True,filters=' ',split=' ',oov_token='UNK')\n",
    "    temp_tokenizer.fit_on_texts(data_frame)\n",
    "    temp_tokenizer.word_index = {elem:i for elem,i in temp_tokenizer.word_index.items() if i<=max_tokenizer_words}\n",
    "    return temp_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_comments = angry.append(sad).append(haha).append(love)\n",
    "total_comments.values[0]\n",
    "comments_tokenizer = tokenizer_in_total(total_comments[0],10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_tokens(tokenizer,sentences,max_words):\n",
    "    return pad_sequences(tokenizer.texts_to_sequences(sentences),\n",
    "                        maxlen=max_words,\n",
    "                         padding='post',truncating='post')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total_comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['despite its propaganda of family values and religiosity the obamacare repeal effort exposed is that the only god republicans worship is the republican party and the dollarthis country has been hopelessly given over to a reprobate mind']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_comments[0:1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenizer for balanced subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_train_value_df = pd.read_csv(os.path.join(path,\"balanced_train_value.csv\"))\n",
    "balanced_train_label_df = pd.read_csv(os.path.join(path,\"balanced_train_label.csv\"))\n",
    "balanced_test_value_df = pd.read_csv(os.path.join(path,\"balanced_test_value.csv\"))\n",
    "balanced_test_label_df = pd.read_csv(os.path.join(path,\"balanced_test_label.csv\"))\n",
    "total_balanced_comments = balanced_train_value_df.append(balanced_test_value_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4420, 2)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_balanced_comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_tokenizer = tokenizer_in_total(total_balanced_comments[\"0\"],10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the pre-trained word-to-vector from golve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "glove_embedding_path = os.path.join(\n",
    "    \"~/data/emotion_detection/data/glove/glove.twitter.27B/glove.twitter.27B.200d.txt\")\n",
    "glove_index = pd.read_table(glove_embedding_path,\n",
    "                            sep=\" \",index_col=0,\n",
    "                            header=None,quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_mean = np.mean(glove_index.mean())\n",
    "glove_std = np.mean(glove_index.std())\n",
    "glove_size = len(glove_index.columns)\n",
    "comments_tokenizer_index = comments_tokenizer.word_index\n",
    "embedding_matrix = np.random.normal(glove_mean,glove_std,(10000+2,glove_size))\n",
    "for word,i in comments_tokenizer_index.items():\n",
    "    if word in comments_tokenizer_index.items():\n",
    "        embedding_matrix[i,:]=glove_index.loc[word].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_tokenizer_index = balanced_tokenizer.word_index\n",
    "balanced_embedding_matrix = np.random.normal(glove_mean,glove_std,(10000+2,glove_size))\n",
    "for word,i in balanced_tokenizer_index.items():\n",
    "    if word in balanced_tokenizer_index.items():\n",
    "        balanced_embedding_matrix[i,:]=glove_index.loc[word].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_df = pd.read_csv(os.path.join(path,\"total_train_value.csv\"))\n",
    "X_test_df = pd.read_csv(os.path.join(path,\"total_test_value.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = to_tokens(comments_tokenizer,X_train_df['0'],50)\n",
    "X_test = to_tokens(comments_tokenizer,X_test_df['0'],50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = pd.read_csv(os.path.join(path,\"total_train_label.csv\"))['0']\n",
    "y_test = pd.read_csv(os.path.join(path,\"total_test_label.csv\"))['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_X_train = to_tokens(balanced_tokenizer,balanced_train_value_df['0'],50)\n",
    "balanced_X_test = to_tokens(balanced_tokenizer,balanced_test_value_df['0'],50)\n",
    "balanced_y_train = balanced_train_label_df[\"0\"]\n",
    "balanced_y_test = balanced_test_label_df[\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# balanced_test_value_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# balanced_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# balanced_test_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.layers import Input,Dense,Embedding,Dropout, Activation\n",
    "from keras.layers import Flatten, Conv1D,MaxPooling1D\n",
    "from keras.layers import LSTM, Bidirectional\n",
    "from keras.models import Model,Sequential\n",
    "from keras import initializers,regularizers,optimizers,layers,constraints\n",
    "from keras.utils import np_utils,multi_gpu_model\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cag_y_train = np_utils.to_categorical(y_train)\n",
    "cag_y_test = np_utils.to_categorical(y_test)\n",
    "balanced_cag_y_train = np_utils.to_categorical(balanced_y_train)\n",
    "balanced_cag_y_test = np_utils.to_categorical(balanced_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deepLSTM1():\n",
    "    inp = Input(shape=(50,), name='input')\n",
    "    x = Embedding(10000+2, glove_size, weights=[embedding_matrix], name='embedding')(inp)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Conv1D(filters=64, kernel_size=5, padding='valid', activation='relu', strides=1, name='conv1')(x)\n",
    "    x = MaxPooling1D(pool_size=4, name='maxpool1')(x)\n",
    "#     x = Bidirectional(LSTM(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1), name='bilstm1')(x)\n",
    "    x = Bidirectional(LSTM(100, return_sequences=True, dropout=0.1, recurrent_dropout=0.1), name='bilstm2')(x)\n",
    "    x = Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1), name='bilstm3')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(100, activation='relu', name='dense1')(x)\n",
    "    x = Dense(50, activation='relu', name='dense2')(x)\n",
    "    x = Dense(4, activation='sigmoid', name='dense3')(x)\n",
    "    model = Model(input=inp, output=x)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:15: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "network_func = deepLSTM1\n",
    "model = network_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.fit(X_train, cag_y_train, batch_size=32, epochs=10, validation_split=0.1)\n",
    "# print('Acc:', model.evaluate(X_test, cag_y_test, batch_size=32)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 4)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_cag_y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3580 samples, validate on 398 samples\n",
      "Epoch 1/10\n",
      "3580/3580 [==============================] - 15s 4ms/step - loss: 1.3853 - acc: 0.2640 - val_loss: 1.3761 - val_acc: 0.2462\n",
      "Epoch 2/10\n",
      "3580/3580 [==============================] - 9s 2ms/step - loss: 1.3561 - acc: 0.3212 - val_loss: 1.3584 - val_acc: 0.3367\n",
      "Epoch 3/10\n",
      "3580/3580 [==============================] - 9s 3ms/step - loss: 1.1990 - acc: 0.4494 - val_loss: 1.2866 - val_acc: 0.3920\n",
      "Epoch 4/10\n",
      "3580/3580 [==============================] - 9s 2ms/step - loss: 1.0438 - acc: 0.5427 - val_loss: 1.2981 - val_acc: 0.4045\n",
      "Epoch 5/10\n",
      "3580/3580 [==============================] - 9s 3ms/step - loss: 0.8352 - acc: 0.6388 - val_loss: 1.3611 - val_acc: 0.4221\n",
      "Epoch 6/10\n",
      "3580/3580 [==============================] - 9s 3ms/step - loss: 0.6786 - acc: 0.7176 - val_loss: 1.5646 - val_acc: 0.4070\n",
      "Epoch 7/10\n",
      "3580/3580 [==============================] - 9s 3ms/step - loss: 0.5580 - acc: 0.7737 - val_loss: 1.6513 - val_acc: 0.4196\n",
      "Epoch 8/10\n",
      "3580/3580 [==============================] - 9s 3ms/step - loss: 0.4514 - acc: 0.8165 - val_loss: 1.8976 - val_acc: 0.4196\n",
      "Epoch 9/10\n",
      "3580/3580 [==============================] - 10s 3ms/step - loss: 0.3623 - acc: 0.8628 - val_loss: 2.0947 - val_acc: 0.4347\n",
      "Epoch 10/10\n",
      "3580/3580 [==============================] - 9s 3ms/step - loss: 0.2917 - acc: 0.8908 - val_loss: 2.3229 - val_acc: 0.4447\n",
      "442/442 [==============================] - 0s 391us/step\n",
      "Acc: 0.47963800945433016\n"
     ]
    }
   ],
   "source": [
    "model.fit(balanced_X_train, balanced_cag_y_train, batch_size=32, epochs=10, validation_split=0.1)\n",
    "print('Acc:', model.evaluate(balanced_X_test, balanced_cag_y_test, batch_size=32)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(model,X_test,y_test):\n",
    "    y_predict = model.predict(X_test)\n",
    "    y_predict = np.array([np.argmax(elem) for elem in y_predict])\n",
    "    res = sum(y_predict==y_test)/len(y_test)\n",
    "    return res\n",
    "def error_collection(X_test_df,y_test,y_predict,file_name):\n",
    "    print(y_test.shape)\n",
    "    print(y_predict.shape)\n",
    "    string_list = [\"angry\",\"sad\",\"haha\",\"love\"]\n",
    "    error_set = X_test_df[y_predict!=y_test]\n",
    "    groud_truth = [string_list[i] for i in y_test[y_predict!=y_test]]\n",
    "    prediction = [string_list[i] for i in y_predict[y_predict!=y_test]]\n",
    "    content = []\n",
    "    content.append(groud_truth)\n",
    "    content.append(prediction)\n",
    "    content.append(list(error_set.values[:,1]))\n",
    "    temp_df = pd.DataFrame(content)\n",
    "    temp_df.rename(columns={\"0\":\"truth\",\"1\":\"prediction\",\"2\":\"content\"})\n",
    "    temp_df = temp_df.transpose()\n",
    "    temp_df.to_csv(file_name)\n",
    "#     return error_set.values[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_y_predict = model.predict(balanced_X_test)\n",
    "balanced_y_predict = np.array([np.argmax(elem) for elem in balanced_y_predict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442,)\n",
      "(442,)\n",
      "error angry percentage 0.20434782608695654\n",
      "error sad percentage 0.25217391304347825\n",
      "error haha percentage 0.2608695652173913\n",
      "error love percentage 0.2826086956521739\n"
     ]
    }
   ],
   "source": [
    "error_collection(balanced_test_value_df,balanced_y_test,balanced_y_predict,\"balanced_test_2.csv\")\n",
    "error_set = pd.read_csv(\"balanced_test_2.csv\")\n",
    "print(\"error angry percentage\",list(error_set[\"0\"]).count(\"angry\")/error_set.shape[0])\n",
    "print(\"error sad percentage\",list(error_set[\"0\"]).count(\"sad\")/error_set.shape[0])\n",
    "print(\"error haha percentage\",list(error_set[\"0\"]).count(\"haha\")/error_set.shape[0])\n",
    "print(\"error love percentage\",list(error_set[\"0\"]).count(\"love\")/error_set.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_predict(predict,label,cag):\n",
    "    predict[label==cag]==cag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-----+------+------+\n",
      "| label\\pre | angry | sad | haha | love |\n",
      "+-----------+-------+-----+------+------+\n",
      "|   angry   |   60  |  20 |  16  |  11  |\n",
      "|    sad    |   35  |  59 |  6   |  17  |\n",
      "|    haha   |   41  |  7  |  49  |  12  |\n",
      "|    love   |   26  |  34 |  5   |  44  |\n",
      "+-----------+-------+-----+------+------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "conf_matrix = PrettyTable()\n",
    "\n",
    "conf_matrix.field_names = [\"label\\\\pre\",\"angry\", \"sad\", \"haha\", \"love\"]\n",
    "\n",
    "conf_matrix.add_row([\"angry\", \n",
    "                     sum(balanced_y_predict[balanced_y_test==0]==0),\n",
    "                     sum(balanced_y_predict[balanced_y_test==0]==1),\n",
    "                     sum(balanced_y_predict[balanced_y_test==0]==2),\n",
    "                     sum(balanced_y_predict[balanced_y_test==0]==3)])\n",
    "conf_matrix.add_row([\"sad\", \n",
    "                     sum(balanced_y_predict[balanced_y_test==1]==0),\n",
    "                     sum(balanced_y_predict[balanced_y_test==1]==1),\n",
    "                     sum(balanced_y_predict[balanced_y_test==1]==2),\n",
    "                     sum(balanced_y_predict[balanced_y_test==1]==3)])\n",
    "conf_matrix.add_row([\"haha\", \n",
    "                     sum(balanced_y_predict[balanced_y_test==2]==0),\n",
    "                     sum(balanced_y_predict[balanced_y_test==2]==1),\n",
    "                     sum(balanced_y_predict[balanced_y_test==2]==2),\n",
    "                     sum(balanced_y_predict[balanced_y_test==2]==3)])\n",
    "conf_matrix.add_row([\"love\", \n",
    "                     sum(balanced_y_predict[balanced_y_test==3]==0),\n",
    "                     sum(balanced_y_predict[balanced_y_test==3]==1),\n",
    "                     sum(balanced_y_predict[balanced_y_test==3]==2),\n",
    "                     sum(balanced_y_predict[balanced_y_test==3]==3)])\n",
    "\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def two_classes_accuracy(y_test,y_predict):\n",
    "    comb = np.array([y_test,y_predict])\n",
    "    count = [1 if abs(i[0]-i[1])<=1 and (i[0]+i[1])!=5 else 0 for i in comb.T]\n",
    "    return sum(count)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_classes_accuracy 0.6334841628959276\n"
     ]
    }
   ],
   "source": [
    "print(\"two_classes_accuracy\",two_classes_accuracy(balanced_y_test, balanced_y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def error_plot(,y_predict):\n",
    "#     f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "#     ax1.plot(x, y)\n",
    "#     ax2.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_embedding():\n",
    "    inp = Input(shape=(50,), name='input')\n",
    "    x = Embedding(10000+2, glove_size, weights=[embedding_matrix], name='embedding')(inp)\n",
    "    model = Model(input=inp,output=x)\n",
    "    model.compile(optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# embedding_create = create_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_create.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i love how liberal keep say the same thing tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lol 1 million new job 11000 less federal job b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>his new general be suppose to keep him in chec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no it doesnt ilive in arizona and we be fine h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arizona be turn blue in no time it go in a tre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>if trump wasnt a racist ignorant bigot he woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>donald trump be on a path to become cemented i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>blame the establishment rino republican and al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>well be still wait to see his amaze wonderful ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>oh cnn lmmfao youre always misinform arent you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>wait for this rag of an outlet to say one thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cnn fake news lieswhy do you feel like you mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hellotrump supporter do you really not have a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ive be try to explain this to you since obama ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>be you kid me arizona voter a in mccains state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>for the trump supporter that i know if you cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>trump want to take away health insurance from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cnn the leader in fake news and the leader in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>hey yall remember when president obama start t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>thats funnyi be currently in arizona and that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>in trump defense he have be push a healthcare ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>it not our president blame the rhino in congre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>they believe the salesman hype and buy a lemon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>arizona please do not believe the lie of cnn i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>if you vote for a clown a circus be what you get</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>the liar n chief say his health care plan be b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>i saw right through him from the very beginnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>theyre idiot for think healthcare cost would g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>he do exactly what we want confuse the leftist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>get back to the white house you knucklehead th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>trump be the best president ever and will be 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>what be go on in this nation \\n\\nmaturity and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>another big lie from cnnthe story talk about a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>totally untrue we trump supporter blame the de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>real or fake news there be lot of u who lose p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>not true it the rinos and the dematurds that f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>president trump accomplishment so far\\n1suprem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>more fake news from cnn sure trump voter be up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>those trump supporter keep say liberal they ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>okive be wait for the trumptydumpty sat on a w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>why be it that when the stock market be at all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>trump have fail to do anything he promise the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>it not trump thats fail be you journalist ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>remember what happen to george hw bushno new t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>negative this supporter feel that donald trump...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>dear cnn president donald j trump can not prev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>isnt that where john mccain be from isnt mccai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>when this be all over and trump be out of offi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>if we do not to set up national health for eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>let it go he try so hard that be not failure t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>how in the world do anyone have any patience w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>well this be expect a potus can say all they w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>consumer confidence at 16 year high unemployme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>really u deplorables never really think it wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>oh cnn you only wish any of these word be true...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>benghazi no grand jury impaneled\\n2 clinton fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>the dow jones rise be go to happen anyway not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>marla voyles you be praise president obama and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>he a child that have no chance of live out his...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    1\n",
       "0   i love how liberal keep say the same thing tha...\n",
       "1   lol 1 million new job 11000 less federal job b...\n",
       "2   his new general be suppose to keep him in chec...\n",
       "3   no it doesnt ilive in arizona and we be fine h...\n",
       "4   arizona be turn blue in no time it go in a tre...\n",
       "5   if trump wasnt a racist ignorant bigot he woul...\n",
       "6   donald trump be on a path to become cemented i...\n",
       "7   blame the establishment rino republican and al...\n",
       "8   well be still wait to see his amaze wonderful ...\n",
       "9   oh cnn lmmfao youre always misinform arent you...\n",
       "10  wait for this rag of an outlet to say one thin...\n",
       "11  cnn fake news lieswhy do you feel like you mus...\n",
       "12  hellotrump supporter do you really not have a ...\n",
       "13  ive be try to explain this to you since obama ...\n",
       "14  be you kid me arizona voter a in mccains state...\n",
       "15  for the trump supporter that i know if you cou...\n",
       "16  trump want to take away health insurance from ...\n",
       "17  cnn the leader in fake news and the leader in ...\n",
       "18                                                NaN\n",
       "19  hey yall remember when president obama start t...\n",
       "20  thats funnyi be currently in arizona and that ...\n",
       "21  in trump defense he have be push a healthcare ...\n",
       "22  it not our president blame the rhino in congre...\n",
       "23  they believe the salesman hype and buy a lemon...\n",
       "24  arizona please do not believe the lie of cnn i...\n",
       "25   if you vote for a clown a circus be what you get\n",
       "26  the liar n chief say his health care plan be b...\n",
       "27  i saw right through him from the very beginnin...\n",
       "28  theyre idiot for think healthcare cost would g...\n",
       "29  he do exactly what we want confuse the leftist...\n",
       "..                                                ...\n",
       "70  get back to the white house you knucklehead th...\n",
       "71  trump be the best president ever and will be 8...\n",
       "72  what be go on in this nation \\n\\nmaturity and ...\n",
       "73  another big lie from cnnthe story talk about a...\n",
       "74  totally untrue we trump supporter blame the de...\n",
       "75  real or fake news there be lot of u who lose p...\n",
       "76  not true it the rinos and the dematurds that f...\n",
       "77  president trump accomplishment so far\\n1suprem...\n",
       "78  more fake news from cnn sure trump voter be up...\n",
       "79  those trump supporter keep say liberal they ha...\n",
       "80  okive be wait for the trumptydumpty sat on a w...\n",
       "81  why be it that when the stock market be at all...\n",
       "82  trump have fail to do anything he promise the ...\n",
       "83  it not trump thats fail be you journalist ther...\n",
       "84  remember what happen to george hw bushno new t...\n",
       "85  negative this supporter feel that donald trump...\n",
       "86  dear cnn president donald j trump can not prev...\n",
       "87  isnt that where john mccain be from isnt mccai...\n",
       "88  when this be all over and trump be out of offi...\n",
       "89  if we do not to set up national health for eve...\n",
       "90  let it go he try so hard that be not failure t...\n",
       "91  how in the world do anyone have any patience w...\n",
       "92  well this be expect a potus can say all they w...\n",
       "93  consumer confidence at 16 year high unemployme...\n",
       "94  really u deplorables never really think it wou...\n",
       "95  oh cnn you only wish any of these word be true...\n",
       "96  benghazi no grand jury impaneled\\n2 clinton fo...\n",
       "97  the dow jones rise be go to happen anyway not ...\n",
       "98  marla voyles you be praise president obama and...\n",
       "99  he a child that have no chance of live out his...\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"annotated_lem.csv\",header=None).iloc[:,1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ftrgen import LexiconFeatures\n",
    "lexftr = LexiconFeatures(lexicondir=os.path.join('emd_data/lexicons/'))\n",
    "lexiconsPath = 'temp.csv'\n",
    "lexftr.build(path=lexiconsPath)\n",
    "lexftr.load(path=lexiconsPath)\n",
    "X_train_lex = lexftr.vectorizeDataset(pd.read_csv(\"annotated_lem.csv\")[\"content\"])\n",
    "# X_dev_lex = lexftr.vectorizeDataset(pd.read_csv(\"test_annotation.csv\")[\"valance\"])\n",
    "X_train_lex = X_train_lex[[c for c in X_train_lex.columns if c != 'tweet']].values\n",
    "# X_dev_lex = X_dev_lex[[c for c in X_dev_lex.columns if c != 'tweet']].values\n",
    "y_train_lex = pd.read_csv(\"test_annotation.csv\",encoding = \"ISO-8859-1\")[\"valance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_lex[y_train_lex==0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.        , 1.        , 5.        , ..., 1.81895348, 1.59862419,\n",
       "        3.05839342],\n",
       "       [1.        , 1.        , 2.        , ..., 0.31445143, 0.76441477,\n",
       "        1.98796245],\n",
       "       [1.        , 6.        , 1.        , ..., 1.34859016, 1.27534351,\n",
       "        2.55683547],\n",
       "       ...,\n",
       "       [4.        , 2.        , 7.        , ..., 1.48308502, 1.86509631,\n",
       "        4.22515118],\n",
       "       [2.        , 1.        , 3.        , ..., 2.78388834, 1.78369785,\n",
       "        3.94216217],\n",
       "       [2.        , 2.        , 5.        , ..., 2.33929821, 1.87791113,\n",
       "        3.76413187]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=16,max_depth=100)\n",
    "rfc.fit(X_train_lex[0:80],y_train_lex[0:80])\n",
    "rfc_y = rfc.predict(X_train_lex[80:100])\n",
    "print(sum(rfc_y==(y_train_lex[80:100]))/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80    False\n",
       "81    False\n",
       "82     True\n",
       "83    False\n",
       "84    False\n",
       "85     True\n",
       "86     True\n",
       "87     True\n",
       "88     True\n",
       "89    False\n",
       "90    False\n",
       "91     True\n",
       "92    False\n",
       "93    False\n",
       "94    False\n",
       "95     True\n",
       "96     True\n",
       "97     True\n",
       "98    False\n",
       "99     True\n",
       "Name: valance, dtype: bool"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rfc_y==y_train_lex[80:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80   -1.0\n",
       "81   -1.0\n",
       "82    1.0\n",
       "83   -1.0\n",
       "84    1.0\n",
       "85   -1.0\n",
       "86   -1.0\n",
       "87    1.0\n",
       "88    1.0\n",
       "89    1.0\n",
       "90   -1.0\n",
       "91    1.0\n",
       "92    1.0\n",
       "93   -1.0\n",
       "94   -1.0\n",
       "95   -1.0\n",
       "96   -1.0\n",
       "97    1.0\n",
       "98    1.0\n",
       "99    1.0\n",
       "Name: valance, dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_lex[80:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.int64' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-f2e7236cb568>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlexftr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlexiconsPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlexftr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlexiconsPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_train_lex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlexftr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorizeDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"annotated_lem.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# X_dev_lex = lexftr.vectorizeDataset(pd.read_csv(\"test_annotation.csv\")[\"valance\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# X_train_lex = X_train_lex[[c for c in X_train_lex.columns if c != 'tweet']].values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cascade/ftrgen.py\u001b[0m in \u001b[0;36mvectorizeDataset\u001b[0;34m(self, tweets, updateInterval)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mftrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorizeDoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweet'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cascade/ftrgen.py\u001b[0m in \u001b[0;36mvectorizeDoc\u001b[0;34m(self, tweet)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvectorizeDoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;31m# tokens = [token.text for token in doc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;31m# tokens = [token.lemma_ for token in doc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.int64' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "from ftrgen import LexiconFeatures\n",
    "lexftr = LexiconFeatures(lexicondir=os.path.join('emd_data/lexicons/'))\n",
    "lexiconsPath = 'temp.csv'\n",
    "lexftr.build(path=lexiconsPath)\n",
    "lexftr.load(path=lexiconsPath)\n",
    "X_train_lex = lexftr.vectorizeDataset(pd.read_csv(os.path.join(path,\"balanced_train_value.csv\"))[\"0\"])\n",
    "X_dev_lex = lexftr.vectorizeDataset(pd.read_csv(os.path.join(path,\"balanced_test_value.csv\"))[\"0\"])\n",
    "X_train_lex = X_train_lex[[c for c in X_train_lex.columns if c != 'tweet']].values\n",
    "X_dev_lex = X_dev_lex[[c for c in X_dev_lex.columns if c != 'tweet']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pd.read_csv(os.path.join(path,\"balanced_train_value.csv\"))[\"0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_ins = PCA(n_components=2)\n",
    "red = pca_ins.fit_transform(X_train_lex)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(red[:,0],red[:,1])\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxb5osQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a298cb4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(red[:,0],red[:,1])\n",
    "plt.xlim(-10, 100)\n",
    "plt.ylim(-20, 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43665158371040724\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=16,max_depth=10)\n",
    "rfc.fit(X_train_lex,balanced_y_train)\n",
    "rfc_y = rfc.predict(X_dev_lex)\n",
    "print(sum(rfc_y==balanced_y_test)/len(balanced_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442,)\n",
      "(442,)\n",
      "two_classes_accuracy 0.6244343891402715\n"
     ]
    }
   ],
   "source": [
    "error_collection(balanced_test_value_df,balanced_y_test,rfc_y,\"balanced_test_lexicon.csv\")\n",
    "print(\"two_classes_accuracy\",two_classes_accuracy(balanced_y_test,rfc_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# kmeans = KMeans(n_clusters=4, n_init=20, n_jobs=4)\n",
    "# kmeans.fit(X_train_lex)\n",
    "# y_km = kmeans.predict(X_dev_lex)\n",
    "# x_test[y_km==y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deepLSTM1_lexi():\n",
    "    inp = Input(shape=(41,), name='input')\n",
    "    x = Embedding(10000+2, glove_size, weights=[embedding_matrix], name='embedding')(inp)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Conv1D(filters=64, kernel_size=5, padding='valid', activation='relu', strides=1, name='conv1')(x)\n",
    "    x = MaxPooling1D(pool_size=4, name='maxpool1')(x)\n",
    "    x = Bidirectional(LSTM(100, return_sequences=True, dropout=0.1, recurrent_dropout=0.1), name='bilstm1')(x)\n",
    "#     x = Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1), name='bilstm2')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(100, activation='relu', name='dense1')(x)\n",
    "    x = Dense(50, activation='relu', name='dense2')(x)\n",
    "    x = Dense(4, activation='sigmoid', name='dense3')(x)\n",
    "    model = Model(input=inp, output=x)\n",
    "#     model = Model(outputs=x, inputs=inp)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4421052631578947"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_lex.reshape(), cag_y_train, batch_size=32, epochs=10, validation_split=0.1)\n",
    "print('Acc:', model.evaluate(X_test, cag_y_test, batch_size=32)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### three classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "Name: lex-NRC10-negative, dtype: float64"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getNRCEmotions(lexicondir):\n",
    "    df = pd.read_csv(os.path.join(lexicondir, 'NRC-emotion-lexicon-wordlevel-v0.92.txt.gz'), sep='\\t')\n",
    "    df.columns = ['word', 'emotion', 'lex-NRC10']\n",
    "    df = pd.pivot_table(df, values='lex-NRC10', index=['word'], columns=['emotion'])\n",
    "    df.reset_index(level=0, inplace=True)\n",
    "    newCols = ['word'] + ['lex-NRC10-' + x for x in df.columns[1:]]\n",
    "    df.columns = newCols\n",
    "    return df\n",
    "lexicon = getNRCEmotions('emd_data/lexicons/')\n",
    "# (lexicon[lexicon[\"emotion\"]==\"positive\"][\"word\"]==\"smut\")\n",
    "lexicon[lexicon[\"word\"]==\"aback\"][\"lex-NRC10-negative\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lexftr = LexiconFeatures(lexicondir=os.path.join('emd_data/lexicons/'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'sample', 'sentence', ',', 'showing', 'off', 'the', 'stop', 'words', 'filtration', '.']\n",
      "['This', 'sample', 'sentence', ',', 'showing', 'stop', 'words', 'filtration', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "  \n",
    "example_sent = \"This is a sample sentence, showing off the stop words filtration.\"\n",
    "  \n",
    "stop_words = set(stopwords.words('english')) \n",
    "  \n",
    "word_tokens = word_tokenize(example_sent) \n",
    "  \n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "  \n",
    "# filtered_sentence = [] \n",
    "  \n",
    "# for w in word_tokens: \n",
    "#     if w not in stop_words: \n",
    "#         filtered_sentence.append(w) \n",
    "print(word_tokens) \n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Anaconda3]",
   "language": "python",
   "name": "Python [Anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
